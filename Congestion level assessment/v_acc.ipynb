{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75010fa5-91f8-4532-888c-e1aef19be0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "os.environ['PROJ_LIB'] = r'D:\\Anaconda\\envs\\TrKG\\Library\\share\\proj'\n",
    "os.environ['GDAL_DATA'] = r'CD:\\Anaconda\\envs\\TrKG\\Library\\share'\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from pyproj import CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d5397-3f05-4a13-85a7-09cd52dca775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Node, Relationship, Graph, NodeMatcher, RelationshipMatcher, Subgraph\n",
    "\n",
    "g = Graph('bolt://localhost:7687',auth=('neo4j','your password'), name = 'trkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f9d4ba2-f0db-498a-baa0-8faa868b429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "from shapely.geometry import Point, LineString, MultiLineString, MultiPoint, GeometryCollection\n",
    "from shapely import geometry\n",
    "from shapely import ops\n",
    "from shapely.ops import split, linemerge\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505e37b6-d1b8-4a2c-a887-d171d92a1622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Derived Projected CRS: PROJCS[\"CGCS2000_3-degree_Gauss-Kruger_CM_120E\",GE ...>\n",
       "Name: CGCS2000_3-degree_Gauss-Kruger_CM_120E\n",
       "Axis Info [cartesian]:\n",
       "- [east]: Easting (metre)\n",
       "- [north]: Northing (metre)\n",
       "Area of Use:\n",
       "- undefined\n",
       "Coordinate Operation:\n",
       "- name: unnamed\n",
       "- method: Transverse Mercator\n",
       "Datum: China 2000\n",
       "- Ellipsoid: CGCS2000\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æŒ‡å®šæ–‡ä»¶è·¯å¾„\n",
    "crs_path = r\"D:/paper2/result/roadcrs.txt\"\n",
    "# è¯»å–æŠ•å½±ä¿¡æ¯\n",
    "with open(crs_path, \"r\") as file:\n",
    "    crs_text = file.read().strip()\n",
    "\n",
    "# å°†æ–‡æœ¬æŠ•å½±ä¿¡æ¯è½¬æ¢ä¸º CRS å¯¹è±¡\n",
    "roadcrs = CRS.from_string(crs_text)\n",
    "roadcrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5efb019c-7662-4330-a529-9a75fb22b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»æœ¬åœ°åŠ è½½ honeycomb_cache\n",
    "with open('D:/paper2/result/honeycomb_cache.pkl', 'rb') as file:\n",
    "    honeycomb_cache = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c03c65-6fa7-4c07-9749-a9b84ba04f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid_time_summary(node_df):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ NumPy ä¼˜åŒ– groupby èšåˆè¿‡ç¨‹\n",
    "    \"\"\"\n",
    "    # æå‰å»é‡ï¼Œè·å–æ¯ä¸ª honeycomb_name å¯¹åº”çš„å›ºå®šå€¼\n",
    "    honeycomb_distances = node_df['honeycomb_name'].drop_duplicates()\n",
    "\n",
    "    # åˆ†ç»„å¹¶ç”¨ NumPy æ“ä½œå®ç°èšåˆ\n",
    "    grouped = node_df.groupby('honeycomb_name')\n",
    "    start_time = grouped['datetime'].min()\n",
    "    end_time = grouped['datetime'].max()\n",
    "    min_name = grouped['trajectory_name'].min()\n",
    "    max_name = grouped['trajectory_name'].max()\n",
    "    count = max_name - min_name + 1\n",
    "\n",
    "\n",
    "    # åˆ›å»º DataFrame\n",
    "    fid_time_summary = pd.DataFrame({\n",
    "        'honeycomb_name': start_time.index,\n",
    "        'start_time': start_time.values,\n",
    "        'end_time': end_time.values,\n",
    "        'count': count.values,\n",
    "        'min_name': min_name.values,\n",
    "        'max_name': max_name.values\n",
    "    })\n",
    "\n",
    "    # è¿‡æ»¤ count > 1\n",
    "    fid_time_summary = fid_time_summary[fid_time_summary['count'] > 1]\n",
    "\n",
    "    # åˆå¹¶ max_distance å’Œ min_distance\n",
    "    fid_time_summary = fid_time_summary.merge(honeycomb_distances, on='honeycomb_name', how='left')\n",
    "\n",
    "    # è®¡ç®—æŒç»­æ—¶é—´\n",
    "    fid_time_summary['duration'] = (fid_time_summary['end_time'] - fid_time_summary['start_time']).dt.total_seconds()\n",
    "\n",
    "    # æŒ‰ start_time æ’åº\n",
    "    fid_time_summary = fid_time_summary.sort_values(by='min_name', ignore_index=True)\n",
    "\n",
    "    return fid_time_summary\n",
    "\n",
    "def get_honeycomb_within(honeycomb_cache, honeycomb_name):\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥åœ¨æœ¬åœ°ç¼“å­˜ä¸­æ˜¯å¦å­˜åœ¨æŒ‡å®šçš„ honeycomb_nameï¼Œå¹¶è¿”å› True å¦‚æœæ‰¾åˆ°ã€‚\n",
    "    \n",
    "    :param honeycomb_cache: æœ¬åœ°åŠ è½½çš„ honeycomb ç¼“å­˜å­—å…¸\n",
    "    :param honeycomb_name: å½“å‰ honeycomb èŠ‚ç‚¹çš„ name\n",
    "    :return: True å¦‚æœå­˜åœ¨ honeycomb_nameï¼ŒFalse å¦åˆ™\n",
    "    \"\"\"\n",
    "    # å¦‚æœåœ¨ç¼“å­˜ä¸­æ‰¾åˆ°æŒ‡å®šçš„ honeycomb_nameï¼Œç«‹å³è¿”å› True\n",
    "    return honeycomb_name in honeycomb_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dec5e48-61b1-4de9-a93a-a71474f14c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŒ‡å®šæ–‡ä»¶çš„å®Œæ•´è·¯å¾„\n",
    "file_path = r'D:\\paper2\\result\\folder_name_list.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    # è¯»å–æ–‡ä»¶å†…å®¹\n",
    "    content = file.read()\n",
    "    \n",
    "    # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨\n",
    "    folder_name = ast.literal_eval(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "174e71e6-89e8-4ae4-832a-84c3f213ce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_filesç¬¬ä¸€ä¸ªå…ƒç´ : 1158\n",
      "selected_filesæœ€åä¸€ä¸ªå…ƒç´ : 4502\n"
     ]
    }
   ],
   "source": [
    "selected_files = folder_name[1156:4500]\n",
    "print(\"selected_filesç¬¬ä¸€ä¸ªå…ƒç´ :\", selected_files[0])\n",
    "print(\"selected_filesæœ€åä¸€ä¸ªå…ƒç´ :\", selected_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b51d567-11bb-4db6-bea9-5bee1c2dd884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder_nameç¬¬ä¸€ä¸ªå…ƒç´ : 1158\n",
      "folder_nameæœ€åä¸€ä¸ªå…ƒç´ : 4502\n"
     ]
    }
   ],
   "source": [
    "selected_files = folder_name[1156:4500]\n",
    "folder_name = selected_files\n",
    "print(\"folder_nameç¬¬ä¸€ä¸ªå…ƒç´ :\", folder_name[0])\n",
    "print(\"folder_nameæœ€åä¸€ä¸ªå…ƒç´ :\", folder_name[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a56049-2195-4feb-97ea-57ddd0c8983a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28892160/28892160 [109:45:42<00:00, 73.12slice/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # å¯¼å…¥ tqdm\n",
    "import gc  # å¯¼å…¥åƒåœ¾å›æ”¶æ¨¡å—\n",
    "\n",
    "# ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨\n",
    "log_dir = r\"C:\\DCLASS\\myJupyter\\paper2\\shanghai_log\\1\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_path = os.path.join(log_dir, \"vehicle_log_2.txt\")\n",
    "\n",
    "\n",
    "batch_size = 250\n",
    "# è®¡ç®—æ€»çš„è¿›åº¦æ¡æ•°ï¼šæ¯ä¸ªæ–‡ä»¶åæœ‰ 8640 æ¬¡è¿­ä»£\n",
    "total_slices = len(folder_name) * 8640\n",
    "\n",
    "# ä½¿ç”¨ tqdm è¿›åº¦æ¡\n",
    "with tqdm(total=total_slices, desc=\"Processing data\", unit=\"slice\") as pbar:\n",
    "    for vehicle_name in folder_name:\n",
    "        \n",
    "        # if vehicle_name != '1355':\n",
    "        #     continue\n",
    "        # if vehicle_name == '3':\n",
    "        #     break\n",
    "        # if vehicle_name != '1354':\n",
    "        #     continue\n",
    "        \n",
    "        # ğŸ”½ å†™å…¥æ—¥å¿—\n",
    "        with open(log_path, \"a\", encoding=\"utf-8\") as log_file:\n",
    "            log_file.write(f\"vehicle_name:\\n {vehicle_name}\\n\")\n",
    "\n",
    "        for five_times_start in range(1, 8641, batch_size):\n",
    "            five_times_end = min(five_times_start + batch_size - 1, 8640)\n",
    "            \n",
    "            # # # è®°å¾—æ³¨é‡Š\n",
    "            # if five_times_start>batch_size:\n",
    "            #     break\n",
    "\n",
    "            # æ„é€ æ‰¹æ¬¡èŒƒå›´æ¡ä»¶\n",
    "            batch_range = ', '.join([f\"'batch_{i}'\" for i in range(five_times_start, five_times_end + 1)])\n",
    "            \n",
    "            # å‚æ•°åŒ–æŸ¥è¯¢ï¼ŒæŸ¥æ‰¾ trajectory_point çš„å±æ€§ä»¥åŠå…¶å…³è”çš„ honeycomb èŠ‚ç‚¹çš„éƒ¨åˆ†å±æ€§\n",
    "            cypher = f\"\"\"\n",
    "                MATCH (tp:trajectory_point)-[:located_in]->(hc:honeycomb)\n",
    "                WHERE tp.vehicle = {vehicle_name} AND tp.batch IN [{batch_range}]\n",
    "                AND (tp)-[:next]-()\n",
    "                RETURN tp.batch AS batch, tp.geometry AS geometry, tp.name AS trajectory_name, tp.vehicle AS vehicle, tp.datetime AS datetime,\n",
    "                       hc.name AS honeycomb_name\n",
    "                ORDER BY tp.name\n",
    "            \"\"\"\n",
    "            # æ‰§è¡ŒæŸ¥è¯¢å¹¶ä¼ å…¥å‚æ•°\n",
    "            result = g.run(cypher).data()\n",
    "\n",
    "            # æ£€æŸ¥æ˜¯å¦æœ‰è¿”å›æ•°æ®\n",
    "            if result:\n",
    "                # å°†ç»“æœè½¬æ¢ä¸º DataFrame\n",
    "                df_result = pd.DataFrame(result)\n",
    "                # ç¡®ä¿ datetime åˆ—æ˜¯ datetime æ ¼å¼\n",
    "                df_result['datetime'] = pd.to_datetime(df_result['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "                #print(f\"df_result:\\n {df_result}\")\n",
    "                \n",
    "                batch_boundaries = df_result['batch'].ne(df_result['batch'].shift()).cumsum()  # å˜åŒ–æ£€æµ‹\n",
    "                # æŒ‰å˜åŒ–è¾¹ç•Œåˆ†å—\n",
    "\n",
    "                for _, group_idx in df_result.groupby(batch_boundaries).groups.items():\n",
    "                    node_df = df_result.loc[group_idx]\n",
    "                    batch_name = node_df['batch'].iloc[0]  # æ¯ä¸ªåˆ†å—çš„ batch_name æ˜¯ä¸€è‡´çš„\n",
    "                \n",
    "                    # trajectory_point èŠ‚ç‚¹æ•°å¤§äº 1 æ‰è¿›è¡Œæ‹¥å µåˆ†æ\n",
    "                    if len(node_df) > 1:\n",
    "                        fid_time_summary = calculate_fid_time_summary(node_df)\n",
    "                        # print(f\"fid_time_summary:\\n {fid_time_summary}\")\n",
    "                        # print(f\"batch_name:\\n {batch_name}\")\n",
    "                        \n",
    "                        if not fid_time_summary.empty:\n",
    "                            # å°† 'geometry' åˆ—ä¸­çš„ WKT å­—ç¬¦ä¸²è½¬æ¢ä¸º Shapely å‡ ä½•å¯¹è±¡\n",
    "                            node_df['geometry'] = node_df['geometry'].apply(wkt.loads)\n",
    "                            # è½¬æ¢ä¸º GeoDataFrame\n",
    "                            node_df = gpd.GeoDataFrame(node_df, geometry='geometry', crs=roadcrs)\n",
    "                            # è®¾ç½® 'trajectory_name' ä¸ºç´¢å¼•\n",
    "                            node_df.set_index('trajectory_name', inplace=True)\n",
    "\n",
    "                            # éå† fid_time_summary çš„æ¯ä¸€è¡Œ\n",
    "                            for index, row in fid_time_summary.iterrows():\n",
    "                                honeycomb_name = row['honeycomb_name']\n",
    "                                # print(f\"\\nRow {index} with FID = {honeycomb_name}\")\n",
    "                                duration = row['duration']\n",
    "                    \n",
    "                                # æ£€æŸ¥ duration æ˜¯å¦ä¸º 0\n",
    "                                if duration == 0:\n",
    "                                    continue  # è·³è¿‡å½“å‰è¡Œ\n",
    "                    \n",
    "    \n",
    "                                # è°ƒç”¨ get_honeycomb_within åˆ¤æ–­\n",
    "                                if not get_honeycomb_within(honeycomb_cache, honeycomb_name):\n",
    "                                    continue\n",
    "                                    \n",
    "                                min_name = row['min_name']\n",
    "                                max_name = row['max_name']\n",
    "                                # ç›´æ¥ä½¿ç”¨ min_name å’Œ max_name ä½œä¸ºè¡Œç´¢å¼•è¿›è¡Œåˆ‡ç‰‡\n",
    "                                between_rows = node_df.loc[min_name:max_name]\n",
    "                                # print(f\"between_rows:\\n {between_rows}\")\n",
    "            \n",
    "                                # æå–å‡ ä½•ç‚¹å¹¶æ„å»º LineString\n",
    "                                line = LineString(between_rows['geometry'].tolist())\n",
    "                                \n",
    "                                # è®¡ç®—æ€»é•¿åº¦\n",
    "                                total_length = line.length\n",
    "                                # print(f\"Total length of the point set: {total_length}\")\n",
    "                                        \n",
    "                                # å¦‚æœæ€»é•¿åº¦å°äº 10 ç±³ï¼Œè§†ä¸ºæ³Šè½¦çŠ¶æ€ï¼ŒåºŸå¼ƒè¯¥æ•°æ®;å¦‚æœæ€»é•¿åº¦å¤§äº 600 ç±³ï¼Œè§†ä¸ºé”™è¯¯æ•°æ®ï¼ŒåºŸå¼ƒè¯¥æ•°æ®\n",
    "                                if total_length <= 20 or total_length >= 600:\n",
    "                                    continue\n",
    "                    \n",
    "                                # è®¡ç®—å¹³å‡é€Ÿåº¦ v_acc\n",
    "                                v_acc = total_length / duration  # ç¡®ä¿å•ä½åŒ¹é…\n",
    "                                \n",
    "                                # æ›´æ–°åŒ¹é…çš„èŠ‚ç‚¹\n",
    "                                cypher_update = f\"\"\"\n",
    "                                MATCH (tp:trajectory_point)\n",
    "                                WHERE tp.vehicle = {vehicle_name} \n",
    "                                  AND tp.batch = '{batch_name}'\n",
    "                                  AND tp.name >= {min_name} AND tp.name <= {max_name}\n",
    "                                SET tp.speed = {v_acc:.3f}\n",
    "                                \"\"\"\n",
    "                                g.run(cypher_update)\n",
    "\n",
    "                                # è¾“å‡ºè°ƒè¯•ä¿¡æ¯\n",
    "                                # print(f\"Average speed (v_acc): {v_acc}\")\n",
    "\n",
    "                # æ¸…é™¤ node_df ç¼“å­˜\n",
    "                if 'node_df' in globals():\n",
    "                    del node_df\n",
    "                if 'fid_time_summary' in globals():\n",
    "                    del fid_time_summary\n",
    "                gc.collect()  # æ‰‹åŠ¨åƒåœ¾å›æ”¶\n",
    "\n",
    "            # æ¸…é™¤ df_result ç¼“å­˜\n",
    "            if 'df_result' in globals():\n",
    "                del df_result\n",
    "            if 'result' in globals():\n",
    "                del result\n",
    "            gc.collect()  # æ‰‹åŠ¨åƒåœ¾å›æ”¶\n",
    "\n",
    "            # æ›´æ–°è¿›åº¦æ¡\n",
    "            pbar.update(five_times_end - five_times_start + 1)\n",
    "\n",
    "    # æœ€åä¸€æ¬¡å…¨å±€åƒåœ¾å›æ”¶\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739c0b3-5072-41ca-ac5b-620f3efabde0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c44299c-a827-46e4-a3fc-dc9bc0dfc74f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a5bf72-6da3-47b2-94a4-ef36b330d06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
